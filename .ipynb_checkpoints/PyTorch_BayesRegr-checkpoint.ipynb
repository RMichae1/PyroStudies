{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -s -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import partial\n",
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import binomial\n",
    "from numpy.random import normal\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch \n",
    "from torch import nn\n",
    "from torch.distributions import constraints\n",
    "\n",
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.optim as optim\n",
    "from pyro.nn import PyroSample\n",
    "from pyro.nn import PyroModule\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "from pyro.infer import SVI\n",
    "from pyro.infer import Trace_ELBO\n",
    "from pyro.infer import Predictive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert pyro.__version__.startswith('1.3')\n",
    "pyro.enable_validation(True)\n",
    "pyro.set_rng_seed(42)\n",
    "pyro.enable_validation(True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a set of randomly distributed features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = normal(0.7, 0.2, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets create an artificial dataset from randomly sampled points\n",
    "data_df = pd.DataFrame({\"F1\": binomial(1, 0.1, 1000), \n",
    "                       \"F2\": binomial(1, 0.2, 1000),\n",
    "                        \"F3\": binomial(1, 0.1, 1000),\n",
    "                       \"F4\": binomial(1, 0.3, 1000), \n",
    "                       \"F5\": binomial(1, 0.5, 1000),\n",
    "                       \"F6\": binomial(1, 0.2, 1000), \n",
    "                       \"F7\": binomial(1, 0.3, 1000),\n",
    "                       \"F8\": binomial(1, 0.5, 1000),\n",
    "                       \"F9\": binomial(1, 0.1, 1000),\n",
    "                       \"F10\": binomial(1, 0.1, 1000),\n",
    "                       \"EXPLAIN\": y})\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make categorical data plottable\n",
    "melted_df = pd.melt(data_df, id_vars=\"EXPLAIN\")\n",
    "melted_df = melted_df[melted_df[\"value\"] != 0][[\"EXPLAIN\", \"variable\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.catplot(x=\"variable\", y=\"EXPLAIN\", kind=\"boxen\", palette=\"dark\",\n",
    "            data=melted_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the data PyTorch objects\n",
    "X = torch.tensor(data_df[[\"F{}\".format(i+1) for i in range(10)]].values, dtype=torch.float)\n",
    "y = torch.tensor(data_df.EXPLAIN.values, dtype=torch.float)\n",
    "\n",
    "INPUT_DIM = 10\n",
    "OUTPUT_DIM = 1\n",
    "ITERATIONS = 1500\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianRegression(PyroModule):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        super().__init__()\n",
    "        self.linear = PyroModule[nn.Linear](in_features, out_features)\n",
    "        self.linear.weight = PyroSample(dist.Normal(0.,1.)\n",
    "                                         .expand([out_features, in_features]).to_event(2))\n",
    "        self.linear.bias = PyroSample(dist.Normal(0., 10.)\n",
    "                                      .expand([out_features]).to_event(1))\n",
    "    \n",
    "    def forward(self, x, y=None):\n",
    "        sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "        mean = self.linear(x).squeeze(-1)\n",
    "        with pyro.plate(\"data\", x.shape[0]):\n",
    "            obs = pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=y)\n",
    "        return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate leaerning objects\n",
    "bayes_reg_model = BayesianRegression(INPUT_DIM, OUTPUT_DIM)\n",
    "guide = AutoDiagonalNormal(bayes_reg_model)\n",
    "\n",
    "adam_opt = pyro.optim.Adam({\"lr\": 0.03})\n",
    "svi = SVI(bayes_reg_model, guide, adam_opt, loss=Trace_ELBO())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyro.clear_param_store()\n",
    "for i in range(ITERATIONS):\n",
    "    # make inference step\n",
    "    loss = svi.step(X, y)\n",
    "    # observe testing\n",
    "    if i % 100 == 0:\n",
    "        print(\"[iteration {}] loss: {}\".format(i, loss / len(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect learned parameters\n",
    "guide.requires_grad_(False)\n",
    "print(\"Learned parameters:\")\n",
    "for name, param in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name))\n",
    "    \n",
    "print(\"Guide parameters:\")\n",
    "print(guide.quantiles([0.25, 0.5, 0.75]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    site_stats = {}\n",
    "    for k, v in samples.items():\n",
    "        site_stats[k] = {\n",
    "            \"mean\": torch.mean(v, 0),\n",
    "            \"std\": torch.std(v,0),\n",
    "            \"5%\": v.kthvalue(int(len(v) * 0.05), dim=0)[0],\n",
    "            \"95%\": v.kthvalue(int(len(v) * 0.95), dim=0)[0],\n",
    "        }\n",
    "    return site_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = Predictive(bayes_reg_model, guide=guide, num_samples=800,\n",
    "                    return_sites=(\"linear.weight\", \"obs\", \"_RETURN\"))\n",
    "samples = predict(X)\n",
    "pred_summary = summary(samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = pred_summary[\"_RETURN\"]\n",
    "y_hat = pred_summary[\"obs\"]\n",
    "predictions = pd.DataFrame({\n",
    "    \"F1\": data_df.F1,\n",
    "    \"F2\": data_df.F2,\n",
    "    \"F3\": data_df.F3,\n",
    "    \"F4\": data_df.F4,\n",
    "    \"F5\": data_df.F5,\n",
    "    \"F6\": data_df.F6,\n",
    "    \"F7\": data_df.F7,\n",
    "    \"F8\": data_df.F8,\n",
    "    \"F9\": data_df.F9,\n",
    "    \"F10\": data_df.F10,\n",
    "    \"mu_mean\": mu[\"mean\"],\n",
    "    \"mu_p95\": mu[\"95%\"],\n",
    "    \"mu_p5\": mu[\"5%\"],\n",
    "    \"y_mean\": y_hat[\"mean\"],\n",
    "    \"y_p95\": y_hat[\"95%\"],\n",
    "    \"y_p5\": y_hat[\"5%\"],\n",
    "    \"Y\": y,\n",
    "})\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_pred = pd.melt(predictions, id_vars=[\"mu_mean\", \"y_mean\", \"Y\"], \n",
    "        value_vars=[\"F{}\".format(i+1) for i in range(10)])\n",
    "melted_mu_pred_df = melted_pred[melted_pred[\"value\"] != 0][[\"mu_mean\", \"variable\"]]\n",
    "melted_y_pred_df = melted_pred[melted_pred[\"value\"] != 0][[\"y_mean\", \"variable\"]]\n",
    "\n",
    "sns.catplot(x=\"variable\", y=\"mu_mean\", kind=\"violin\", bw=.2, palette=\"Set2\", data=melted_mu_pred_df)\n",
    "sns.catplot(x=\"variable\", y=\"y_mean\", kind=\"violin\", bw=.2, palette=\"Set2\", data=melted_y_pred_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot uncertainty\n",
    "weights = samples[\"linear.weight\"]\n",
    "weights = weights.reshape(weights.shape[0], 10)\n",
    "gamma_1 = weights[:, 1]\n",
    "gamma_12 = weights[:,1] + weights[:, 2]\n",
    "gamma_123 = weights[:,1] + weights[:, 2] + weights[:, 3]\n",
    "\n",
    "fig = plt.figure(figsize=(10,6))\n",
    "sns.distplot(gamma_1, kde_kws={\"label\": \"Feat 1\"})\n",
    "sns.distplot(gamma_12, kde_kws={\"label\": \"Intersection 1,2\"})\n",
    "sns.distplot(gamma_123, kde_kws={\"label\": \"Intersection 1,2,3\"})\n",
    "fig.suptitle(\"Density of Fit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's make the inference more explicit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write model without PyroModule usage\n",
    "def model(F1, F2, F3, EXPLAIN):\n",
    "    \"\"\"\n",
    "    Model to take into account F1-3 and their interaction with explicit priors.\n",
    "    \"\"\"\n",
    "    assert len(F1) == len(F2) == len(F3) == len(EXPLAIN)\n",
    "    f = pyro.sample(\"f\", dist.Normal(0., 10.))\n",
    "    b_f1 = pyro.sample(\"bF1\", dist.Normal(0., 1.))\n",
    "    b_f2 = pyro.sample(\"bF2\", dist.Normal(0., 1.))\n",
    "    b_f3 = pyro.sample(\"bF3\", dist.Normal(0., 1.))\n",
    "    b_f12 = pyro.sample(\"bF12\", dist.Normal(0., 1.))\n",
    "    b_f13 = pyro.sample(\"bF13\", dist.Normal(0., 1.))\n",
    "    b_f23 = pyro.sample(\"bF23\", dist.Normal(0., 1.))\n",
    "    b_f123 = pyro.sample(\"bF123\", dist.Normal(0., 1.))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Uniform(0., 10.))\n",
    "    mean = f + b_f1*F1 + b_f2*F2 + b_f3*F3 + b_f12*F1*F2 + b_f13*F1*F3 + b_f23*F2*F3 + b_f123*F1*F2*F3\n",
    "    # step over independent events\n",
    "    with pyro.plate(\"data\", len(F1)):\n",
    "        pyro.sample(\"obs\", dist.Normal(mean, sigma), obs=EXPLAIN)\n",
    "        \n",
    "def guide(F1, F2, F3, EXPLAIN):\n",
    "    f_loc = pyro.param(\"f_loc\", torch.tensor(0.))\n",
    "    f_scale = pyro.param(\"f_scale\", torch.tensor(1.), \n",
    "                        constraint=constraints.positive)\n",
    "    sigma_loc = pyro.param(\"sigma_loc\", torch.tensor(1.), \n",
    "                        constraint=constraints.positive)\n",
    "    weights_loc = pyro.param(\"weights_loc\", torch.randn(7))\n",
    "    weights_scale = pyro.param(\"weights_scale\", torch.ones(7),\n",
    "                              constraint=constraints.positive)\n",
    "    \n",
    "    f = pyro.sample(\"f\", dist.Normal(f_loc, f_scale))\n",
    "    b_f1 = pyro.sample(\"bF1\", dist.Normal(weights_loc[0], weights_scale[0]))\n",
    "    b_f2 = pyro.sample(\"bF2\", dist.Normal(weights_loc[1], weights_scale[1]))\n",
    "    b_f3 = pyro.sample(\"bF3\", dist.Normal(weights_loc[2], weights_scale[2]))\n",
    "    b_f12 = pyro.sample(\"bF12\", dist.Normal(weights_loc[3], weights_scale[3]))\n",
    "    b_f13 = pyro.sample(\"bF13\", dist.Normal(weights_loc[4], weights_scale[4]))\n",
    "    b_f23 = pyro.sample(\"bF23\", dist.Normal(weights_loc[5], weights_scale[5]))\n",
    "    b_f123 = pyro.sample(\"bF123\", dist.Normal(weights_loc[6], weights_scale[6]))\n",
    "    sigma = pyro.sample(\"sigma\", dist.Normal(sigma_loc, torch.tensor(0.05)))\n",
    "    mean = f + b_f1*F1 + b_f2*F2 + b_f3*F3 + b_f12*F1*F2 + b_f13*F1*F3 + b_f23*F2*F3 + b_f123*F1*F2*F3\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary(samples):\n",
    "    \"\"\"\n",
    "    Utility function to summarise the fit\n",
    "    \"\"\"\n",
    "    site_stats = {}\n",
    "    for site_name, values in samples.items():\n",
    "        marginal_site = pd.DataFrame(values)\n",
    "        describe = marginal_site.describe(percentiles=[.05, 0.25, 0.5, 0.75, 0.95]).transpose()\n",
    "        site_stats[site_name] = describe[[\"mean\", \"std\", \"5%\", \"25%\", \"50%\", \"75%\", \"95%\"]]\n",
    "    return site_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svi = SVI(model, guide, optim.Adam({'lr': 0.05}), loss=Trace_ELBO())\n",
    "\n",
    "f1, f2, f3 = X[:,1], X[:,2], X[:,3]\n",
    "\n",
    "pyro.clear_param_store()\n",
    "ITERATION = 500\n",
    "\n",
    "for i in range(ITERATIONS):\n",
    "    elbo = svi.step(f1, f2, f3, y)\n",
    "    if i % 100 == 0:\n",
    "        print(\"[STEP {}] Elbo loss: {}\".format(i, elbo))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSDA",
   "language": "python",
   "name": "lsda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
